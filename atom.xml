<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jhonlibai&#39;s Blog</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://jhonlibai.top/"/>
  <updated>2017-12-18T08:46:23.985Z</updated>
  <id>http://jhonlibai.top/</id>
  
  <author>
    <name>Jhonlibai</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>python学习日志2</title>
    <link href="http://jhonlibai.top/2017/12/18/python%E6%97%A5%E5%BF%972/"/>
    <id>http://jhonlibai.top/2017/12/18/python日志2/</id>
    <published>2017-12-18T06:04:08.000Z</published>
    <updated>2017-12-18T08:46:23.985Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="闲话"><a href="#闲话" class="headerlink" title="闲话"></a>闲话</h2><p>时隔一个多月，（额，不，快两个月了。汗！）我终于想起来写我的学习日志了。上个星期我“又双”找了一些爬虫的学习视频。以下是我根据视频里的讲解将代码摘录出的。（侵，删）貌似也没人会看我的blog呢。该系列的爬虫视频一共4期，我才看了2期。感觉讲得很好。所以我也把人家的教学内容里的代码给搬过来了，汗！这次搬运过来的2篇爬虫练习是：1.爬取豆瓣电影top250（网上好多类似爬取豆瓣的。）；2.爬取网易云音乐热评。</p>
<h2 id="第一篇：爬取豆瓣电影top250"><a href="#第一篇：爬取豆瓣电影top250" class="headerlink" title="第一篇：爬取豆瓣电影top250"></a>第一篇：爬取豆瓣电影top250</h2><a id="more"></a>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">open_url</span><span class="params">(url)</span>:</span></div><div class="line">    headers = &#123;</div><div class="line">        <span class="string">'user-agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'</span></div><div class="line">    &#125;</div><div class="line">    res = requests.get(url, headers= headers)</div><div class="line">    <span class="keyword">return</span> res</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_movies</span><span class="params">(res)</span>:</span></div><div class="line">    soup = BeautifulSoup(res.text, <span class="string">'html.parser'</span>)</div><div class="line"></div><div class="line">    <span class="comment">#电影名</span></div><div class="line">    movies = []</div><div class="line">    targets = soup.find_all(<span class="string">'div'</span>, class_=<span class="string">'hd'</span>)</div><div class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> targets:</div><div class="line">        movies.append(each.a.span.text)</div><div class="line"></div><div class="line">    <span class="comment">#评分</span></div><div class="line">    ranks = []</div><div class="line">    targets = soup.find_all(<span class="string">'span'</span>, class_=<span class="string">'rating_num'</span>)</div><div class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> targets:</div><div class="line">        ranks.append(<span class="string">'评分: %s'</span> % each.text)</div><div class="line"></div><div class="line">    <span class="comment">#资料</span></div><div class="line">    messages = []</div><div class="line">    targets = soup.find_all(<span class="string">'div'</span>, class_=<span class="string">'bd'</span>)</div><div class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> targets:</div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            messages.append(each.p.text.split(<span class="string">'\n'</span>)[<span class="number">1</span>].strip() + each.p.text.split(<span class="string">'\n'</span>)[<span class="number">2</span>].strip())</div><div class="line">        <span class="keyword">except</span>:</div><div class="line">            <span class="keyword">continue</span></div><div class="line"></div><div class="line">    result = []</div><div class="line">    length = len(movies)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(length):</div><div class="line">        result.append(movies[i] + ranks[i] + messages[i] + <span class="string">'\n'</span>)</div><div class="line"></div><div class="line">    <span class="keyword">return</span>  result</div><div class="line"></div><div class="line"><span class="comment">#找出一共多少个页面</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_depth</span><span class="params">(res)</span>:</span></div><div class="line">    soup = BeautifulSoup(res.text, <span class="string">'html.parser'</span>)</div><div class="line">    depth = soup.find(<span class="string">'span'</span>, class_=<span class="string">'next'</span>).previous_sibling.previous_sibling.text</div><div class="line">    <span class="keyword">return</span> int(depth)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">    host = <span class="string">"https://movie.douban.com/top250"</span></div><div class="line">    res = open_url(host)</div><div class="line">    depth = find_depth(res)</div><div class="line"></div><div class="line">    result = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(depth):</div><div class="line">        url = host + <span class="string">'/?start='</span> + str(<span class="number">25</span> * i)</div><div class="line">        res = open_url(url)</div><div class="line">        result.extend(find_movies(res))</div><div class="line">        </div><div class="line">    <span class="comment">#将爬取的资源写入txt文本。</span></div><div class="line">    <span class="keyword">with</span> open(<span class="string">"豆瓣TOP250电影.txt"</span>, <span class="string">"w"</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</div><div class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> result:</div><div class="line">            f.write(each)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure>
<p>这段代码主要运用了python的3个主流模块requests，beautifsoup,re(正则)。在主函数中作者还加了一个将爬取的资源写入text文本操作。在find_movies函数中，作者分别抓取了电影名称，评分，资料。然后在利用find_depth函数统计网页的页数。将上述爬取的功能在统计出的页数内循环。最后写入txt文档。</p>
<h2 id="第二篇：爬取网易云音乐热评"><a href="#第二篇：爬取网易云音乐热评" class="headerlink" title="第二篇：爬取网易云音乐热评"></a>第二篇：爬取网易云音乐热评</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> json</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_hot_comments</span><span class="params">(res)</span>:</span></div><div class="line">    comments_json = json.loads(res.text)</div><div class="line">    hot_comments = comments_json[<span class="string">'hotComments'</span>]</div><div class="line">    <span class="keyword">with</span> open(<span class="string">'hot_comments.txt'</span>, <span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> file:</div><div class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> hot_comments:</div><div class="line">            file.write(each[<span class="string">'user'</span>][<span class="string">'nickname'</span>] + <span class="string">' :\n\n'</span>)</div><div class="line">            file.write(each[<span class="string">'content'</span>] + <span class="string">'\n'</span>)</div><div class="line">            file.write(<span class="string">"----------------------------------\n"</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_comments</span><span class="params">(url)</span>:</span></div><div class="line">    name_id = url.split(<span class="string">'='</span>)[<span class="number">1</span>]</div><div class="line"></div><div class="line">    headers = &#123;</div><div class="line">        <span class="string">'user-agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'</span>,</div><div class="line">        <span class="string">'referer'</span>: <span class="string">'http://music.163.com/song?id=299116'</span></div><div class="line">    &#125;</div><div class="line">    params = <span class="string">"kVOK9yH1g693xp2kbk / C / TQ6HdH / 8ksAbmy8lusmgpPjwDnEvOZn5CdJAcfbQ6DbKOGbwfCVtZWHFxayfe9jDW77R4aITNkgJoStKlPNjM0ABvKBYOo2yuvBdP3d + B5g5uO1Me5M7 + CTwRQvnZNp39zwQ3P4kJ2ab0txZEDt5H38FwqtJ4YlaIqoE5JA + 2hb5OsPJBX4xzUyfzSLlkJTMclcADmsV8OqTw4QyKSMyqk "</span></div><div class="line">    encSecKey = <span class="string">"2f5e2a9247b9ebb24da8cf961dc5bd0e7db6d220fe41e06fe10cd936ebf8df629b3336fd8475198c206bb45816ddabbc9c7cfbe9894603d9ab1589857e8eb498312cf1360ab2b3db35be6648fe80091b21454c89e453e4546613f93b98197bc2e40e7e1c01b0f43d19a113f58939127dacaecfd670ed5d242cd19e2a2aed5262"</span></div><div class="line">    data = &#123;</div><div class="line">        <span class="string">"params"</span>:params,</div><div class="line">        <span class="string">"encSecKey"</span>:encSecKey</div><div class="line">    &#125;</div><div class="line">    target_url = <span class="string">"http://music.163.com/weapi/v1/resource/comments/R_SO_4_&#123;&#125;?csrf_token="</span>.format(name_id)</div><div class="line">    res = requests.post(target_url, headers=headers,data=data)</div><div class="line">    <span class="keyword">return</span> res</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">    url = input(<span class="string">"请输入链接地址："</span>)</div><div class="line">    res = get_comments(url)</div><div class="line">    hot_comments = get_hot_comments(res)</div><div class="line"></div><div class="line">    <span class="keyword">with</span> open(<span class="string">"res.txt"</span>, <span class="string">"w"</span>, encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> file:</div><div class="line">        file.write(res.text)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure>
<p>以上是爬取网易云音乐网页版单首歌曲的热门评论的代码。你只要输入链接地址就可以爬取热门评论。要注意的是在get_comments函数中headers，params，encSeckey所赋值的一长串字符是需要在网页的“检查”中摘取，具体摘取方法请点击链接：<a href="https://www.bilibili.com/video/av15834715/#page=4/" target="_blank" rel="external">爬取网易云音乐热门评论</a> </p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;闲话&quot;&gt;&lt;a href=&quot;#闲话&quot; class=&quot;headerlink&quot; title=&quot;闲话&quot;&gt;&lt;/a&gt;闲话&lt;/h2&gt;&lt;p&gt;时隔一个多月，（额，不，快两个月了。汗！）我终于想起来写我的学习日志了。上个星期我“又双”找了一些爬虫的学习视频。以下是我根据视频里的讲解将代码摘录出的。（侵，删）貌似也没人会看我的blog呢。该系列的爬虫视频一共4期，我才看了2期。感觉讲得很好。所以我也把人家的教学内容里的代码给搬过来了，汗！这次搬运过来的2篇爬虫练习是：1.爬取豆瓣电影top250（网上好多类似爬取豆瓣的。）；2.爬取网易云音乐热评。&lt;/p&gt;
&lt;h2 id=&quot;第一篇：爬取豆瓣电影top250&quot;&gt;&lt;a href=&quot;#第一篇：爬取豆瓣电影top250&quot; class=&quot;headerlink&quot; title=&quot;第一篇：爬取豆瓣电影top250&quot;&gt;&lt;/a&gt;第一篇：爬取豆瓣电影top250&lt;/h2&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>python日志1</title>
    <link href="http://jhonlibai.top/2017/10/23/python%E6%97%A5%E5%BF%971/"/>
    <id>http://jhonlibai.top/2017/10/23/python日志1/</id>
    <published>2017-10-23T07:02:39.000Z</published>
    <updated>2017-10-23T07:54:52.501Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>前几天在网易云课堂学了几集Python抓取实战。跟着视频的节奏尝试学着敲了下来。代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> json</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCommentCounts</span><span class="params">(newsurl)</span>:</span></div><div class="line">    m = re.search(<span class="string">'doc-i(.*).shtml'</span>, newsurl)</div><div class="line">    newsid = m.group(<span class="number">1</span>)</div><div class="line">    comments = requests.get(commenturl.format(newsid))</div><div class="line">    jd = json.loads(comments.text.strip(<span class="string">'var data='</span>))</div><div class="line">    <span class="keyword">return</span> jd[<span class="string">'result'</span>][<span class="string">'count'</span>][<span class="string">'total'</span>]</div><div class="line">   </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getNewsDetail</span><span class="params">(newsurl)</span>:</span></div><div class="line">    result = &#123;&#125;</div><div class="line">    res = requests.get(newsurl)</div><div class="line">    res.encoding = <span class="string">'utf-8'</span></div><div class="line">    soup = BeautifulSoup(res.text,<span class="string">'html.parser'</span>)</div><div class="line">    result[<span class="string">'title'</span>] = soup.select(<span class="string">'#artibodyTitle'</span>)[<span class="number">0</span>].text</div><div class="line">    result[<span class="string">'newssource'</span>] = soup.select(<span class="string">'.time-source span a'</span>)[<span class="number">0</span>].text</div><div class="line">    timesource = soup.select(<span class="string">'.time-source'</span>)[<span class="number">0</span>].contents[<span class="number">0</span>].strip()</div><div class="line">    result[<span class="string">'dt'</span>] = datetime.strptime(timesource,<span class="string">'%Y年%m月%d日%H:%M'</span>)</div><div class="line">    result[<span class="string">'article'</span>] = <span class="string">'@'</span>.join([p.text.strip() <span class="keyword">for</span> p <span class="keyword">in</span> soup.select(<span class="string">'#artibody p'</span>)[:<span class="number">-1</span>]])</div><div class="line">    result[<span class="string">'editor'</span>] = soup.select(<span class="string">'.article-editor'</span>)[<span class="number">0</span>].text</div><div class="line">    result[<span class="string">'comments'</span>] = getCommentCounts(newsurl)</div><div class="line">    <span class="keyword">return</span> result</div><div class="line"></div><div class="line">newsurl = <span class="string">'http://news.sina.com.cn/c/nd/2017-10-21/doc-ifymzzpv8209433.shtml'</span></div><div class="line">commenturl = <span class="string">'http://comment5.news.sina.com.cn/page/info?version=1&amp;format=js&amp;channel=gn&amp;newsid=comos-&#123;&#125;&amp;group=&amp;compress=0&amp;ie=utf-8&amp;oe=utf-8&amp;page=1&amp;page_size=20'</span></div><div class="line">print(getNewsDetail(newsurl))</div><div class="line"></div><div class="line"></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>message = <span class="string">'''interpreter</span></div><div class="line"><span class="string"><span class="meta">... </span>prompt'''</span></div></pre></td></tr></table></figure></p>
<p>这是抓取了一个新浪新闻标题为“清华生会游泳才能毕业？新生:游泳比考清华容易”的文章。抓取内容如下：<br><img src="http://ov67n3jz8.bkt.clouddn.com/%E6%8A%93%E5%8F%96%E5%86%85%E5%AE%B9.png" alt="抓取内容"><br>这段代码中定义了2个函数一个是获取文章细节：<br>    def getNewsDetail(newsurl):<br>另一个是获取文章评论数：<br>    def getCommentCounts(newsurl):<br>函数内是类似如下相关剖析代码：<br><img src="http://ov67n3jz8.bkt.clouddn.com/%E4%B8%BE%E4%BE%8B%E8%AF%B4%E6%98%8E.png" alt="举例说明"><br>主要运用的python模块库有Request、BeautifulSoup4、re、json、datetime.<br>以上完结，撒花。<br>下次更新同时抓取多个文章内容。</p>
]]></content>
    
    <summary type="html">
    
      &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;前几天在网易云课堂学了几集Python抓取实战。跟着视频的节奏尝试学着敲了下
    
    </summary>
    
    
      <category term="学习" scheme="http://jhonlibai.top/tags/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>随笔4</title>
    <link href="http://jhonlibai.top/2017/10/02/%E9%9A%8F%E7%AC%944/"/>
    <id>http://jhonlibai.top/2017/10/02/随笔4/</id>
    <published>2017-10-02T11:58:11.000Z</published>
    <updated>2017-10-02T12:17:44.896Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>今天是10/1长假的第二天，一如往日的无所事是。下午跑去网吧上了半天的网。一个人时间长了，连选择游戏都是一件困惑的事情，已经不能像以前那样对某款游戏迷恋很长时间。现在只是打发时间的工具，一切的事物对我而言，看上去是那么的乏陈无味。感觉自己得了一种病，一种矫情的病。不然也不会在这写下不知所云的话语。<br>日子像一条干渴的河床，期待一场突如其来暴风雨。</p>
]]></content>
    
    <summary type="html">
    
      &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;今天是10/1长假的第二天，一如往日的无所事是。下午跑去网吧上了半天的网。一
    
    </summary>
    
    
      <category term="日记" scheme="http://jhonlibai.top/tags/%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>python学习日志0</title>
    <link href="http://jhonlibai.top/2017/09/25/Python%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%970/"/>
    <id>http://jhonlibai.top/2017/09/25/Python学习日志0/</id>
    <published>2017-09-25T02:49:45.192Z</published>
    <updated>2017-09-25T04:05:52.087Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>  在8月份我捣鼓了1个星期的hexo + next的静态博客。在观摩别人的博客，和在阅读了网上许多的配置教程。磕磕绊绊中，我也搭建了一个自己的博客。并且注册了一个自己域名jhonlibai.top。虽然搭建了博客，可自己是个懒猪，并没有更好地扩展和美化它。不过能够搭建自己的个人域名博客，还是很开心，有些自豪的。当初有这个搭建博客的想法，完全是因为被它美观、简洁的外表所吸引。<br>  然而搭建了之后，我就发现一个问题。怎么更新和管理。hexo是一个静态的博客框架。然，还缺少一些可以在线管理自己的博客的功能。不过有问题都可以找度娘。然后我们可以发现一个大家都积极推荐的一款软件markdown编辑器。用它就可以编辑文章内容了。不过要新建文章你还是要用到git。这在搭建hexo就要用到。嗯，，，说了那么多。好像和Python没关系。哈哈哈哈哈！<br>  接触Python是9月份的事了，就酱，下回想起在表。</p>
]]></content>
    
    <summary type="html">
    
      &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;  在8月份我捣鼓了1个星期的hexo + next的静态博客。在观摩别人的
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>随笔3</title>
    <link href="http://jhonlibai.top/2017/08/29/%E9%9A%8F%E7%AC%943/"/>
    <id>http://jhonlibai.top/2017/08/29/随笔3/</id>
    <published>2017-08-29T08:13:50.607Z</published>
    <updated>2017-08-29T08:22:52.213Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="生无可恋"><a href="#生无可恋" class="headerlink" title="生无可恋"></a>生无可恋</h1><blockquote>
<ul>
<li>睡醒了，起床么？不想起，起来也不知道干啥，没意思。</li>
<li>再睡会？睡不着了，也没意思。</li>
<li>终于起来了，先把电脑打开吧，看看手机，一个消息都没有，没意思。</li>
<li>刷个牙洗个脸？给谁看啊，不去，没意思。</li>
<li>电脑开了，学习？学你妹，没意思。</li>
<li>那看会视频？看啥，啥都不想看，没意思。</li>
<li>算了还是打局DOTA吧，输了，MLGB，好没意思。</li>
<li>再打一局吧，赢了，好像TM也没啥意思。</li>
<li>中午了，吃个饭？吃啥，不想吃，没意思。</li>
<li>喊谁出去玩吧？开个手机把通讯录从头看到尾，好像喊谁都不合适，算了，没意思。</li>
<li>看看跑男好了，嘻嘻嘻嘻嘻嘻哈哈哈哈哈哈，好没意思。</li>
<li>好饿，点个外卖吧，虽然不知道这是午饭还是晚饭。</li>
<li>好饿，外卖呢。</li>
<li>好饿，外卖呢！</li>
<li><p>好饿，我要饿死了……………………………………………………</p>
</li>
<li><p>外卖终于来了，呼噜噜噜，饱了，刚才为什么不让我饿死？真没意思。</p>
</li>
</ul>
</blockquote>
<ul>
<li>作者：大熊猫不含糖</li>
<li>链接：<a href="https://www.zhihu.com/question/31519677/" target="_blank" rel="external">https://www.zhihu.com/question/31519677/</a> answer/70523620</li>
<li>来源：知乎</li>
</ul>
<hr>
<ul>
<li><p><img src="http://ov67n3jz8.bkt.clouddn.com/%E7%94%9F%E6%97%A0%E5%8F%AF%E6%81%8B.jpg" alt="生物可恋"></p>
  <embed src="//music.163.com/style/swf/widget.swf?sid=496948864&type=2&auto=0&width=320&height=66" width="340" height="86" allownetworking="all"></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;生无可恋&quot;&gt;&lt;a href=&quot;#生无可恋&quot; class=&quot;head
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>随笔2</title>
    <link href="http://jhonlibai.top/2017/08/25/%E9%9A%8F%E7%AC%942/"/>
    <id>http://jhonlibai.top/2017/08/25/随笔2/</id>
    <published>2017-08-25T07:28:11.000Z</published>
    <updated>2017-08-29T08:25:30.794Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="获取虾米唱片墙"><a href="#获取虾米唱片墙" class="headerlink" title="获取虾米唱片墙"></a>获取虾米唱片墙</h2><ul>
<li><p>封面：<img src="http://ov67n3jz8.bkt.clouddn.com/%E6%B3%B0%E5%8B%92%20%E6%91%A9%E7%94%9F.jpg" alt="泰勒 摩生"></p>
  <script type="text/javascript" src="http://www.xiami.com/widget/player-multi?uid=32334217&sid=1772499047,1772499044,1773446930,1772341517,1772472237,1769759045,1769575204,3611826,&width=400&height=300&mainColor=FF8719&backColor=494949&autoplay=0&mode=js"></script>

</li>
</ul>
<p>失败！！！</p>
]]></content>
    
    <summary type="html">
    
      &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;获取虾米唱片墙&quot;&gt;&lt;a href=&quot;#获取虾米唱片墙&quot; class
    
    </summary>
    
    
      <category term="音乐" scheme="http://jhonlibai.top/tags/%E9%9F%B3%E4%B9%90/"/>
    
  </entry>
  
  <entry>
    <title>随笔1</title>
    <link href="http://jhonlibai.top/2017/08/24/%E9%9A%8F%E7%AC%941/"/>
    <id>http://jhonlibai.top/2017/08/24/随笔1/</id>
    <published>2017-08-24T04:07:16.000Z</published>
    <updated>2017-08-25T06:35:06.561Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="七牛云存图试用篇"><a href="#七牛云存图试用篇" class="headerlink" title="七牛云存图试用篇"></a>七牛云存图试用篇</h1><ul>
<li><p>图片1: <img src="http://ov67n3jz8.bkt.clouddn.com/singing.jpg" alt="张喆"></p>
</li>
<li><p>图片2: <img src="http://ov67n3jz8.bkt.clouddn.com/Jhon&amp;Emilia.jpg" alt="Jhon&amp;Emilia"></p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;七牛云存图试用篇&quot;&gt;&lt;a href=&quot;#七牛云存图试用篇&quot; cla
    
    </summary>
    
    
      <category term="照片" scheme="http://jhonlibai.top/tags/%E7%85%A7%E7%89%87/"/>
    
  </entry>
  
  <entry>
    <title>随笔0</title>
    <link href="http://jhonlibai.top/2017/08/23/%E9%9A%8F%E7%AC%940/"/>
    <id>http://jhonlibai.top/2017/08/23/随笔0/</id>
    <published>2017-08-23T08:28:08.000Z</published>
    <updated>2017-08-25T06:41:13.889Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h3 id="今天分享一首歌，填充一下内容"><a href="#今天分享一首歌，填充一下内容" class="headerlink" title="今天分享一首歌，填充一下内容"></a>今天分享一首歌，填充一下内容</h3><ul>
<li>专辑图片 <img src="http://ov67n3jz8.bkt.clouddn.com/Hotaru.jpg" alt="Hotaru"></li>
<li>插画师：Rella</li>
</ul>
<ul>
<li>歌曲：Hotaru</li>
<li>作者：Last Number </li>
<li><p>演唱：花近</p>
  <embed src="http://www.xiami.com/widget/32334217_1796482789/singlePlayer.swf" type="application/x-shockwave-flash" width="257" height="33" wmode="transparent">




</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h3 id=&quot;今天分享一首歌，填充一下内容&quot;&gt;&lt;a href=&quot;#今天分享一首歌
    
    </summary>
    
    
      <category term="音乐" scheme="http://jhonlibai.top/tags/%E9%9F%B3%E4%B9%90/"/>
    
  </entry>
  
  <entry>
    <title>Welcome</title>
    <link href="http://jhonlibai.top/2017/08/17/Welcome/"/>
    <id>http://jhonlibai.top/2017/08/17/Welcome/</id>
    <published>2017-08-17T02:03:39.000Z</published>
    <updated>2017-08-23T08:22:33.837Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>这是一个无聊的页面。。。。。。。。。。。。。。。。。。。。。。。</p>
<h2 id="Welcome"><a href="#Welcome" class="headerlink" title="Welcome"></a>Welcome</h2><a id="more"></a>
<h3 id="图片插入"><a href="#图片插入" class="headerlink" title="图片插入"></a>图片插入</h3><ul>
<li>图片1：<a href="http://jhonlibai.top"><img src="http://ohecg7vrp.bkt.clouddn.com/14.gif" alt="jhonlibai" title="blog"></a></li>
</ul>
<ul>
<li><p>图片2：<img src="http://upload-images.jianshu.io/upload_images/3876828-a4346506018aa44f.gif?imageMogr2/auto-orient/strip" alt="面对疾风吧" title="哈赛给 啊痛"></p>
</li>
<li><p>图片3: <img src="file:///F:/blog/source/img/singing.jpg" alt="张喆"></p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一个无聊的页面。。。。。。。。。。。。。。。。。。。。。。。&lt;/p&gt;
&lt;h2 id=&quot;Welcome&quot;&gt;&lt;a href=&quot;#Welcome&quot; class=&quot;headerlink&quot; title=&quot;Welcome&quot;&gt;&lt;/a&gt;Welcome&lt;/h2&gt;
    
    </summary>
    
    
      <category term="第一个试用页面" scheme="http://jhonlibai.top/tags/%E7%AC%AC%E4%B8%80%E4%B8%AA%E8%AF%95%E7%94%A8%E9%A1%B5%E9%9D%A2/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://jhonlibai.top/2017/08/11/hello-world/"/>
    <id>http://jhonlibai.top/2017/08/11/hello-world/</id>
    <published>2017-08-11T06:53:39.881Z</published>
    <updated>2017-08-18T04:53:41.396Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<a id="more"></a>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;h3 id=&quot;Create-a-new-post&quot;&gt;&lt;a href=&quot;#Create-a-new-post&quot; class=&quot;headerlink&quot; title=&quot;Create a new post&quot;&gt;&lt;/a&gt;Create a new post&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ hexo new &lt;span class=&quot;string&quot;&gt;&quot;My New Post&quot;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://hexo.io/docs/writing.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Writing&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Run-server&quot;&gt;&lt;a href=&quot;#Run-server&quot; class=&quot;headerlink&quot; title=&quot;Run server&quot;&gt;&lt;/a&gt;Run server&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ hexo server&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
